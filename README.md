# ğŸ“„ ContextSmith â€“ A Context-Aware AI Assistant

## ğŸš€ Overview
**ContextSmith** is an intelligent, context-aware AI assistant that understands user questions in relation to provided or retrieved context.  
Unlike basic chatbots that respond blindly, ContextSmith **evaluates whether it has enough information before answering** â€” and takes autonomous steps to get what it needs.

---

## ğŸ§  How It Works
At its core, ContextSmith uses **LangChain** with a custom **tool-based reasoning system** and a local **Llama 3 model** via **Ollama**.  
The assistantâ€™s decision-making flow:

1. **Judge context presence** â€“ Checks if the user provided enough background.
2. **Retrieve missing context** â€“ Uses a search tool if information is insufficient.
3. **Validate relevance** â€“ Ensures the retrieved context matches the query.
4. **Separate context & question** â€“ Prepares a clean, structured prompt for the AI.
5. **Answer with confidence** â€“ Combines all relevant details into a clear response.

---

## ğŸ› ï¸ Tech Stack
- **Python 3.10+**
- [LangChain](https://www.langchain.com/) â€“ Agent orchestration
- [Ollama](https://ollama.com/) â€“ Local Llama 3 model
- [Streamlit](https://streamlit.io/) â€“ Web-based UI
- Document parsing: `python-docx`, `PyPDF2`, `chardet`
- Optional: Web search integration (Tavily API or similar)

---

## ğŸ“‚ Project Structure
```
ContextSmith/
â”‚
â”œâ”€â”€ tools/                 # Custom LangChain tools
â”‚   â”œâ”€â”€ context_presence_judge.py
â”‚   â”œâ”€â”€ web_search_tool.py
â”‚   â”œâ”€â”€ context_relevance_checker.py
â”‚   â””â”€â”€ context_splitter.py
â”‚
â”œâ”€â”€ prompts/               # Prompt templates for tools
â”‚   â”œâ”€â”€ context_judge_prompt.txt
â”‚   â”œâ”€â”€ relevance_prompt.txt
â”‚   â””â”€â”€ splitter_prompt.txt
â”‚
â”œâ”€â”€ ui/                    # Streamlit interface
â”‚   â””â”€â”€ streamlit_ui.py
â”‚
â”œâ”€â”€ agent/                 # Agent configuration
â”‚   â””â”€â”€ agent_runner.py
â”‚
â”œâ”€â”€ main.py                # Entry point for local CLI mode
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

1ï¸âƒ£ **Clone the repository**
```bash
git clone https://github.com/YoussefYasserAbdelkader/ContextSmith.git
cd ContextSmith
```

2ï¸âƒ£ **Create and activate a virtual environment**
```bash
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows
```

3ï¸âƒ£ **Install dependencies**
```
pip install -r requirements.txt
```

4ï¸âƒ£ **Install Ollama and pull Llama 3**
```
ollama pull llama3
```

---

## â–¶ï¸ Running the Project

### **Streamlit Web App**
```
streamlit run ui/streamlit_ui.py
```
Open your browser at `http://localhost:....`.

### **CLI Mode**
```
python main.py
```

---

## ğŸ“‘ Features
- **Document upload** â€“ Supports `.pdf`, `.docx`, `.txt` files
- **Automatic context analysis** â€“ Determines whether more info is needed
- **Web search fallback** â€“ Retrieves missing context dynamically
- **Context validation** â€“ Ensures the information is relevant
- **Local AI processing** â€“ No cloud API required (privacy-friendly)
- **Interactive UI** â€“ Streamlit-based interface for seamless use


---

## ğŸ“Œ Roadmap
- [ ] Add memory for multi-turn context
- [ ] Support more file formats (Markdown, HTML)
- [ ] Integrate vector database for long-term knowledge storage
- [ ] Add speech-to-text for voice queries

---

## ğŸ¤ Contributing
Pull requests are welcome! Please fork the repo and create a new branch for your feature or bugfix.


This project is licensed under the MIT License â€“ see the [LICENSE](LICENSE) file for details.
